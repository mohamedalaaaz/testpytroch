{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM60SfE4zuzu162UhX9OiIW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedalaaaz/testpytroch/blob/main/f-35.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "xm0Yi9pqZVu3",
        "outputId": "dfd773cc-68e6-4186-d48b-85f4f2a04dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--data_dir DATA_DIR] [--out_dir OUT_DIR]\n",
            "                                [--epochs EPOCHS] [--batch_size BATCH_SIZE]\n",
            "                                [--lr LR] [--weight_decay WEIGHT_DECAY]\n",
            "                                [--patience PATIENCE] [--freeze_backbone]\n",
            "                                [--no_freeze_backbone]\n",
            "                                [--num_workers NUM_WORKERS]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-6648930d-3886-4c96-9516-43ef7e8f14fc.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "import os, math, time, copy, json, random\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms, models\n",
        "from torcheval.metrics import MulticlassAccuracy, MulticlassF1Score\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def seed_all(seed=42):\n",
        "    random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True; torch.backends.cudnn.benchmark = False\n",
        "seed_all(42)\n",
        "\n",
        "def build_transforms(img_size=256, crop=224):\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.RandomResizedCrop(crop, scale=(0.7, 1.0), ratio=(0.75, 1.33)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.05),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.CenterCrop(crop),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    return train_tf, eval_tf\n",
        "\n",
        "def make_datasets(data_dir):\n",
        "    train_tf, eval_tf = build_transforms()\n",
        "    train_ds = datasets.ImageFolder(Path(data_dir)/\"train\", transform=train_tf)\n",
        "    val_ds   = datasets.ImageFolder(Path(data_dir)/\"val\",   transform=eval_tf)\n",
        "    test_ds  = datasets.ImageFolder(Path(data_dir)/\"test\",  transform=eval_tf)\n",
        "    return train_ds, val_ds, test_ds\n",
        "\n",
        "def make_sampler(dataset):\n",
        "    # Handle class imbalance with WeightedRandomSampler\n",
        "    targets = [y for _, y in dataset.samples]\n",
        "    class_count = torch.bincount(torch.tensor(targets))\n",
        "    class_weights = 1.0 / torch.clamp(class_count.float(), min=1.0)\n",
        "    sample_weights = [class_weights[t] for t in targets]\n",
        "    return WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "def make_loaders(train_ds, val_ds, test_ds, batch_size=32, num_workers=4):\n",
        "    sampler = make_sampler(train_ds)\n",
        "    train_ld = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=num_workers, pin_memory=True)\n",
        "    val_ld   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    test_ld  = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    return train_ld, val_ld, test_ld\n",
        "\n",
        "def build_model(num_classes, freeze_backbone=True):\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    if freeze_backbone:\n",
        "        for p in model.parameters(): p.requires_grad = False\n",
        "    in_feat = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(in_feat, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, num_classes):\n",
        "    model.eval()\n",
        "    acc = MulticlassAccuracy(num_classes=num_classes).to(DEVICE)\n",
        "    f1  = MulticlassF1Score(num_classes=num_classes, average=\"macro\").to(DEVICE)\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)\n",
        "        logits = model(x)\n",
        "        preds = logits.argmax(1)\n",
        "        acc.update(preds, y)\n",
        "        f1.update(preds, y)\n",
        "        total += y.size(0)\n",
        "        correct += (preds == y).sum().item()\n",
        "    return {\"acc\": acc.compute().item(), \"f1_macro\": f1.compute().item(), \"raw_acc\": correct/total}\n",
        "\n",
        "def train(\n",
        "    data_dir=\"data\",\n",
        "    out_dir=\"runs/aircraft_cls\",\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    patience=5,\n",
        "    freeze_backbone=True,\n",
        "    num_workers=4\n",
        "):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    train_ds, val_ds, test_ds = make_datasets(data_dir)\n",
        "    class_names = train_ds.classes\n",
        "    num_classes = len(class_names)\n",
        "    with open(Path(out_dir)/\"classes.json\", \"w\") as f:\n",
        "        json.dump(class_names, f, indent=2)\n",
        "\n",
        "    train_ld, val_ld, test_ld = make_loaders(train_ds, val_ds, test_ds, batch_size, num_workers)\n",
        "    model = build_model(num_classes, freeze_backbone).to(DEVICE)\n",
        "\n",
        "    # If backbone is frozen, only optimize the head\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    best_wts = copy.deepcopy(model.state_dict())\n",
        "    best_val = -1.0\n",
        "    bad_epochs = 0\n",
        "\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        n = 0\n",
        "        t0 = time.time()\n",
        "        for x, y in train_ld:\n",
        "            x, y = x.to(DEVICE, non_blocking=True), y.to(DEVICE, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            logits = model(x)\n",
        "            loss = ce(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * y.size(0)\n",
        "            n += y.size(0)\n",
        "\n",
        "        scheduler.step()\n",
        "        train_loss = running_loss / max(n, 1)\n",
        "\n",
        "        val_metrics = evaluate(model, val_ld, num_classes)\n",
        "        val_score = val_metrics[\"f1_macro\"]  # monitor macro F1\n",
        "        elapsed = time.time() - t0\n",
        "\n",
        "        print(f\"Epoch {epoch:02d}/{epochs} | \"\n",
        "              f\"train_loss={train_loss:.4f} | \"\n",
        "              f\"val_acc={val_metrics['acc']:.4f} | \"\n",
        "              f\"val_f1={val_metrics['f1_macro']:.4f} | \"\n",
        "              f\"time={elapsed:.1f}s\")\n",
        "\n",
        "        # Checkpoint\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": optimizer.state_dict(),\n",
        "            \"class_names\": class_names\n",
        "        }, Path(out_dir)/\"last.pt\")\n",
        "\n",
        "        if val_score > best_val:\n",
        "            best_val = val_score\n",
        "            best_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_wts, Path(out_dir)/\"best_weights.pt\")\n",
        "            bad_epochs = 0\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            if bad_epochs >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    # Load best and evaluate on test\n",
        "    model.load_state_dict(best_wts)\n",
        "    torch.save(model.state_dict(), Path(out_dir)/\"best_weights.pt\")\n",
        "    test_metrics = evaluate(model, test_ld, num_classes)\n",
        "    with open(Path(out_dir)/\"test_metrics.json\", \"w\") as f:\n",
        "        json.dump(test_metrics, f, indent=2)\n",
        "    print(\"Test:\", test_metrics)\n",
        "    print(\"Classes:\", class_names)\n",
        "    return model, class_names\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--data_dir\", type=str, default=\"data\")\n",
        "    ap.add_argument(\"--out_dir\", type=str, default=\"runs/aircraft_cls\")\n",
        "    ap.add_argument(\"--epochs\", type=int, default=20)\n",
        "    ap.add_argument(\"--batch_size\", type=int, default=32)\n",
        "    ap.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    ap.add_argument(\"--weight_decay\", type=float, default=1e-4)\n",
        "    ap.add_argument(\"--patience\", type=int, default=5)\n",
        "    ap.add_argument(\"--freeze_backbone\", action=\"store_true\")\n",
        "    ap.add_argument(\"--no_freeze_backbone\", dest=\"freeze_backbone\", action=\"store_false\")\n",
        "    ap.set_defaults(freeze_backbone=True)\n",
        "    ap.add_argument(\"--num_workers\", type=int, default=4)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    train(\n",
        "        data_dir=args.data_dir,\n",
        "        out_dir=args.out_dir,\n",
        "        epochs=args.epochs,\n",
        "        batch_size=args.batch_size,\n",
        "        lr=args.lr,\n",
        "        weight_decay=args.weight_decay,\n",
        "        patience=args.patience,\n",
        "        freeze_backbone=args.freeze_backbone,\n",
        "        num_workers=args.num_workers\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def build_transform(img_size=256, crop=224):\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.CenterCrop(crop),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    ])\n",
        "\n",
        "def load_model(weights_path, classes_path):\n",
        "    class_names = json.load(open(classes_path))\n",
        "    model = models.resnet18(weights=None)\n",
        "    in_feat = model.fc.in_features\n",
        "    model.fc = torch.nn.Sequential(torch.nn.Dropout(0.2), torch.nn.Linear(in_feat, len(class_names)))\n",
        "    model.load_state_dict(torch.load(weights_path, map_location=DEVICE))\n",
        "    model.eval().to(DEVICE)\n",
        "    return model, class_names\n",
        "\n",
        "def predict(img_path, weights=\"runs/aircraft_cls/best_weights.pt\", classes=\"runs/aircraft_cls/classes.json\"):\n",
        "    tf = build_transform()\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    x = tf(img).unsqueeze(0).to(DEVICE)\n",
        "    model, class_names = load_model(weights, classes)\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=1)[0]\n",
        "        conf, idx = torch.max(probs, dim=0)\n",
        "    return class_names[idx.item()], conf.item()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"image\", type=str)\n",
        "    ap.add_argument(\"--weights\", type=str, default=\"runs/aircraft_cls/best_weights.pt\")\n",
        "    ap.add_argument(\"--classes\", type=str, default=\"runs/aircraft_cls/classes.json\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    label, conf = predict(args.image, args.weights, args.classes)\n",
        "    print(f\"Prediction: {label} (confidence {conf:.3f})\")\n"
      ],
      "metadata": {
        "id": "VqJfhtSMZeiu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}